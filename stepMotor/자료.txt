face tracking
import 기본라이

elif 여러개의 조건중 원하는 것을 고른다
코드에서 먼저 추적기 유형
(BOOSTING, MIL, KCF, TLD, MEDIANFLOW, GOTURN, MOSSE 또는 CSRT
선택하여 추적기를 설정합니다. 가장 빠른것은 KCF

얼굴 인식에 사용하는 Haar Cascades 는 머신러닝 기반의 오브젝트 검출 알고리즘
특징(feature)을 기반으로 비디오 또는 이미지에서 오브젝트를 검출하기 위해 사용됩니다. 
직사각형 영역으로 구성되는 특징을 사용기 때문에 픽셀을 직접 사용할 때 보다 동작 속도가 빠릅니다. 


gray는 input 값으로 이전에 얻은 grayscale image입력 하는 것을 의미한다.
openface로 face image data를 추출할 때는 haar_cascade로 추출한 것과 같은 수준으로 픽셀 값을 크게 할 것) 

각 후보 rectangle이 얼마나 많은 neighbors를 가져야하는지를 명시하는 파라미터이다.
cvtColor rgb 컬러 설정
equalizeHist 히스토그램 평활화
detectMultiScale 다양한 크기의 얼굴검출

detectmultiscale()의 리턴값은 void나 a list of rectangles 로 return 된다

detectMultiScale()는 검출된 얼굴이미지(사각형)에 대한 x, y, width, height 로 구성된 list를 반환하는 듯 

face_cascade = cv2.CascadeClassifier()

faces  = face_cascade.detectMultiScale(grayframe, 1.1, 5, 0, (30, 30))

faces  = face_cascade.detectMultiScale(gray, 1.3 , 5)
cascadeclassifier의 detectMultiScale함수에 grayscale이미지를 입력하여 얼굴 검출
위치는(x,y,w,h)와 같은 튜플 x,y는 검출된 얼굴의 좌상단 위치
w,h는 가로 세로 크기

cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)
frame 값에 rgb입력해서 색 설정 p1,p2는 두께
cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2) 

print('det w : %d ' % w + 'h : %d ' % h)
det은 행렬식 계산

k = cv2.waitKey(1) & 0xff 64비트
k = cv2.waitKey(1) &      32비트

if k == 27 : break
esc의 아스키코드값 27





----------------------------------------------------------------------------------------------------------------

import cv2
import sys

#카메라 번호
# /dev/video0 = 0
# 이곳에 동영상 파일명의 위치를 넣어주면 동영상 재생으로 동작함
CAM_ID = 0

# 추적기능 상태
#얼굴 인식
TRACKING_STATE_CHECK = 0
#얼굴인식 위치를 기반으로 추적 기능 초기화
TRACKING_STATE_INIT  = 1
#추적 동작
TRACKING_STATE_ON    = 2

#OpenCV 버전 확인
(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')

if __name__ == '__main__' :
    #버전 출력
    print((cv2.__version__).split('.'))

    # 트레킹 함수 선택
    tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN']
    # 기본 KCF(Kernelized Correlation Filters)가 속도가 빠르다.
    tracker_type = tracker_types[2]

    # OpenCV 서브 버전별 함수 호출명이 다르다.
    if int(minor_ver) < 3:
        #3.2 이하
        tracker = cv2.Tracker_create(tracker_type)
    else:
        #3.3 이상
        if tracker_type == 'BOOSTING':
            tracker = cv2.TrackerBoosting_create()
        if tracker_type == 'MIL':
            tracker = cv2.TrackerMIL_create()
        if tracker_type == 'KCF':
            tracker = cv2.TrackerKCF_create()
        if tracker_type == 'TLD':
            tracker = cv2.TrackerTLD_create()
        if tracker_type == 'MEDIANFLOW':
            tracker = cv2.TrackerMedianFlow_create()
        if tracker_type == 'GOTURN':
            tracker = cv2.TrackerGOTURN_create()

    #카메라 열기
    video = cv2.VideoCapture(CAM_ID)

    #카메라가 정상적으로 열리지 않았다면 프로그램 종료
    if not video.isOpened():
        print("Could not open video")
        sys.exit()

    #얼굴인식 함수 생성
    face_cascade = cv2.CascadeClassifier()
    #얼굴인식용 haar 불러오기
    face_cascade.load('/usr/local/share/OpenCV/haarcascades/haarcascade_frontalface_default.xml')

    #추적 상태 저장용 변수
    TrackingState = 0
    #추적 영역 저장용 변수
    TrackingROI = (0,0,0,0)

    #프로그램 시작
    while True:
        #카메라에서 1 frame 읽어오기
        ok, frame = video.read()
        #영상이 없다면 프로그램 종료를 위해 while 문 빠져나옴
        if not ok:
            break

        #추적 상태가 얼굴 인식이면 얼굴 인식 기능 동작
        #처음에 무조건 여기부터 들어옴
        if TrackingState == TRACKING_STATE_CHECK:
            #흑백 변경
            grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            #히스토그램 평활화(재분할)
            grayframe = cv2.equalizeHist(grayframe)
            #얼굴 인식
            faces  = face_cascade.detectMultiScale(grayframe, 1.1, 5, 0, (30, 30))

detectmultiscale()의 리턴값은 void나 a list of rectangles 로 return 된다
detectMultiScale()는 검출된 얼굴이미지(사각형)에 대한 x, y, width, height 로 구성된 list를 반환하는 듯 

            #얼굴이 1개라도 잡혔다면
            if len(faces) > 0:
                #얼굴 인식된 위치 및 크기 얻기
                x,y,w,h = faces[0]
                #인식된 위치및 크기를 TrackingROI에 저장
                TrackingROI = (x,y,w,h)
                #인식된 얼굴 표시 순식간에 지나가서 거의 볼수 없음(녹색)
                cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3, 4, 0)
                #추적 상태를 추적 초기화로 변경
                TrackingState = TRACKING_STATE_INIT
                print('det w : %d ' % w + 'h : %d ' % h)

        #추적 초기화
        #얼굴이 인식되면 동작함
        elif TrackingState == TRACKING_STATE_INIT:
            #추적 함수 초기화
            #얼굴인식으로 가져온 위치와 크기를 함께 넣어준다.
            ok = tracker.init(frame, TrackingROI)
            if ok:
                #성공하였다면 추적 동작상태로 변경
                TrackingState = TRACKING_STATE_ON
                print('tracking init succeeded')
            else:
                #실패하였다면 얼굴 인식상태로 다시 돌아감
                TrackingState = TRACKING_STATE_CHECK
                print('tracking init failed')

        #추적 동작
        elif TrackingState == TRACKING_STATE_ON:
            #추적
            ok, TrackingROI = tracker.update(frame)
            if ok:
                #추적 성공했다면
                p1 = (int(TrackingROI[0]), int(TrackingROI[1]))
                p2 = (int(TrackingROI[0] + TrackingROI[2]), int(TrackingROI[1] + TrackingROI[3]))
                #화면에 박스로 표시 (파랑)
                cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)
                print('success x %d ' % (int(TrackingROI[0])) + 'y %d ' % (int(TrackingROI[1])) +
                        'w %d ' % (int(TrackingROI[2])) + 'h %d ' % (int(TrackingROI[3])))
            else:
                print('Tracking failed')

                TrackingState = TRACKING_STATE_CHECK

        #화면에 카메라 영상 표시
        #추적된 박스가 있으면 같이 표시됨
        cv2.imshow("Tracking", frame)

        #ESC키를 누르면 break로 종료
        k = cv2.waitKey(1) & 0xff
        if k == 27 : break